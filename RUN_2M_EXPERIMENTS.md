# ðŸš€ 2Mæ•°æ®å®žéªŒæŒ‡å—

## ðŸ“Š å®žéªŒç›®æ ‡

åœ¨2M NYCæ•°æ®é›†ä¸ŠéªŒè¯ï¼š
1. DCRNN baseline + Flow Adapter
2. STFormer baseline + Flow Adapter
3. STGCN baseline + Flow Adapter (å¯é€‰)

é¢„æœŸç»“æžœï¼šæ¯”96kæå‡å¹…åº¦æ›´å¤§ï¼ˆå‚è€ƒST-ResNet: 33% â†’ 55%ï¼‰

---

## ðŸ“ å‡†å¤‡2Mæ•°æ®é›†

### æ–¹æ³•1ï¼šå¦‚æžœä½ å·²æœ‰2Mæ•°æ®

å°† `nyc_2m_jan_feb_with_intents.parquet` ä¸Šä¼ åˆ°GitHubä»“åº“çš„ `data/` æ–‡ä»¶å¤¹

**æ³¨æ„**ï¼šGitHubæœ‰100MBæ–‡ä»¶é™åˆ¶ï¼Œéœ€è¦ä½¿ç”¨Git LFS

```bash
# åœ¨æœ¬åœ°
cd "C:\coding\PhD-DS\didi-code\colab_upload"

# å®‰è£…Git LFS
git lfs install

# è¿½è¸ªå¤§æ–‡ä»¶
git lfs track "data/*.parquet"
git add .gitattributes

# å¤åˆ¶2Mæ•°æ®ï¼ˆä»Žæœ¬åœ°è·¯å¾„ï¼‰
copy "D:\nyc-taxi-project\processed\nyc_2m_jan_feb_with_intents.parquet" data\

# æäº¤å¹¶æŽ¨é€
git add data/nyc_2m_jan_feb_with_intents.parquet
git commit -m "Add 2M dataset"
git push
```

### æ–¹æ³•2ï¼šä¸Šä¼ åˆ°Google Driveï¼ˆæŽ¨èï¼‰

**ä½ çš„æ•°æ®å·²åœ¨Google Driveä¸Š**ï¼Œç›´æŽ¥åœ¨Colabä¸­ä½¿ç”¨ï¼š

```python
# åœ¨Colabä¸­
from google.colab import drive
drive.mount('/content/drive')

# å¤åˆ¶æ•°æ®åˆ°å·¥ä½œç›®å½•ï¼ˆä¿®æ”¹è·¯å¾„ä¸ºä½ çš„å®žé™…è·¯å¾„ï¼‰
!cp "/content/drive/MyDrive/nyc_2m_jan_feb_with_intents.parquet" data/

# éªŒè¯
!ls -lh data/*.parquet
```

### æ–¹æ³•3ï¼šä»ŽKaggleä¸‹è½½ï¼ˆå¦‚æžœä½ ä¸Šä¼ åˆ°Kaggleï¼‰

```python
# åœ¨Colabä¸­
!pip install kaggle -q
!mkdir -p ~/.kaggle
!cp /path/to/kaggle.json ~/.kaggle/
!kaggle datasets download -d your-username/nyc-2m-intents
!unzip nyc-2m-intents.zip -d data/
```

---

## ðŸŽ¯ å®Œæ•´çš„Colabè®­ç»ƒè„šæœ¬ï¼ˆ2Mæ•°æ®ï¼‰

å¤åˆ¶è¿™ä¸ªåˆ°Colabï¼ŒæŒ‰é¡ºåºè¿è¡Œï¼š

### Cell 1: å…‹éš†ä»“åº“
```python
!git clone https://github.com/wbhtcl2019/flow-intent-adapter.git
%cd flow-intent-adapter
```

### Cell 2: æ£€æŸ¥GPUå’Œæ˜¾å­˜
```python
import torch
import os

print(f"PyTorch: {torch.__version__}")
print(f"CUDA: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    gpu_name = torch.cuda.get_device_name(0)
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
    print(f"GPU: {gpu_name}")
    print(f"Memory: {gpu_memory:.2f} GB")

    # æ£€æŸ¥æ˜¯å¦æ˜¯å¥½GPU
    if 'T4' in gpu_name or 'V100' in gpu_name or 'A100' in gpu_name:
        print("âœ… GPUè¶³å¤Ÿå¼ºï¼Œå¯ä»¥è·‘2Mæ•°æ®")
    else:
        print("âš ï¸  GPUè¾ƒå¼±ï¼Œå»ºè®®å‡å°batch_size")
```

### Cell 3: æŒ‚è½½Driveå¹¶å¤åˆ¶2Mæ•°æ®ï¼ˆå¦‚æžœéœ€è¦ï¼‰
```python
from google.colab import drive
drive.mount('/content/drive')

# å¤åˆ¶2Mæ•°æ®ï¼ˆä¿®æ”¹è·¯å¾„ä¸ºä½ çš„å®žé™…è·¯å¾„ï¼‰
!cp "/content/drive/MyDrive/nyc_2m_jan_feb_with_intents.parquet" data/

# éªŒè¯æ•°æ®
!ls -lh data/
```

### Cell 4: å®‰è£…ä¾èµ–
```python
!pip install -r requirements.txt -q
```

### Cell 5: éªŒè¯æ–‡ä»¶
```python
import os

files_to_check = [
    ('train_baselines.py', 10000),
    ('baselines/dcrnn_baseline.py', 10000),
    ('baselines/stformer_baseline.py', 10000),
    ('data/nyc_2m_jan_feb_with_intents.parquet', 50000000)  # è‡³å°‘50MB
]

print("ðŸ“ æ–‡ä»¶æ£€æŸ¥:")
all_good = True
for fname, min_size in files_to_check:
    if os.path.exists(fname):
        size = os.path.getsize(fname)
        size_mb = size / (1024*1024)
        if size >= min_size:
            print(f"âœ… {fname} ({size_mb:.2f} MB)")
        else:
            print(f"âš ï¸  {fname} ({size_mb:.2f} MB) - å¯èƒ½å¤ªå°")
            all_good = False
    else:
        print(f"âŒ {fname} - ç¼ºå¤±!")
        all_good = False

if all_good:
    print("\nðŸŽ‰ æ‰€æœ‰æ–‡ä»¶å°±ç»ªï¼")
else:
    print("\nâš ï¸  è¯·æ£€æŸ¥æ–‡ä»¶")
```

### Cell 6: ã€å®žéªŒ1ã€‘DCRNN Baseline (2M)
```python
# é¢„è®¡è®­ç»ƒæ—¶é—´: 4-6å°æ—¶
!python train_baselines.py \
    --model dcrnn \
    --data_path data/nyc_2m_jan_feb_with_intents.parquet \
    --epochs 100 \
    --lr 0.0001 \
    --batch_size 32 \
    --hidden_dim 64 \
    --n_tiles 32 \
    --closeness_len 12

# è®­ç»ƒå®ŒæˆåŽä¿å­˜ç»“æžœ
!cp dcrnn_baseline_best.pth /content/drive/MyDrive/checkpoints/dcrnn_baseline_2M.pth
```

### Cell 7: ã€å®žéªŒ2ã€‘DCRNN + Flow Adapter (2M)
```python
# é¢„è®¡è®­ç»ƒæ—¶é—´: 5-7å°æ—¶
!python train_baselines.py \
    --model dcrnn \
    --use_flow \
    --data_path data/nyc_2m_jan_feb_with_intents.parquet \
    --epochs 100 \
    --lr 0.001 \
    --alpha 0.02 \
    --batch_size 32 \
    --hidden_dim 64 \
    --latent_dim 64 \
    --n_tiles 32 \
    --closeness_len 12

# ä¿å­˜ç»“æžœ
!cp dcrnn_flow_best.pth /content/drive/MyDrive/checkpoints/dcrnn_flow_2M.pth
```

### Cell 8: ã€å®žéªŒ3ã€‘STFormer Baseline (2M)
```python
# é¢„è®¡è®­ç»ƒæ—¶é—´: 3-5å°æ—¶
!python train_baselines.py \
    --model stformer \
    --data_path data/nyc_2m_jan_feb_with_intents.parquet \
    --epochs 100 \
    --lr 0.0001 \
    --batch_size 32 \
    --hidden_dim 64 \
    --n_tiles 32 \
    --closeness_len 12

# ä¿å­˜
!cp stformer_baseline_best.pth /content/drive/MyDrive/checkpoints/stformer_baseline_2M.pth
```

### Cell 9: ã€å®žéªŒ4ã€‘STFormer + Flow Adapter (2M)
```python
# é¢„è®¡è®­ç»ƒæ—¶é—´: 4-6å°æ—¶
!python train_baselines.py \
    --model stformer \
    --use_flow \
    --data_path data/nyc_2m_jan_feb_with_intents.parquet \
    --epochs 100 \
    --lr 0.001 \
    --alpha 0.02 \
    --batch_size 32 \
    --hidden_dim 64 \
    --latent_dim 64 \
    --n_tiles 32 \
    --closeness_len 12

# ä¿å­˜
!cp stformer_flow_best.pth /content/drive/MyDrive/checkpoints/stformer_flow_2M.pth
```

### Cell 10: ã€å¯é€‰ã€‘STGCNå®žéªŒ
```python
# Baseline
!python train_baselines.py \
    --model stgcn \
    --data_path data/nyc_2m_jan_feb_with_intents.parquet \
    --epochs 100 \
    --lr 0.0001 \
    --batch_size 32

# + Flow
!python train_baselines.py \
    --model stgcn \
    --use_flow \
    --data_path data/nyc_2m_jan_feb_with_intents.parquet \
    --epochs 100 \
    --lr 0.001 \
    --alpha 0.02 \
    --batch_size 32
```

### Cell 11: ç»“æžœæ±‡æ€»
```python
import torch
import pandas as pd

results = []

models = [
    ('dcrnn_baseline_best.pth', 'DCRNN Baseline'),
    ('dcrnn_flow_best.pth', 'DCRNN + Flow'),
    ('stformer_baseline_best.pth', 'STFormer Baseline'),
    ('stformer_flow_best.pth', 'STFormer + Flow'),
]

for fname, name in models:
    if os.path.exists(fname):
        ckpt = torch.load(fname, map_location='cpu')
        mae = ckpt.get('best_mae', 'N/A')
        epoch = ckpt.get('epoch', 'N/A')
        results.append({
            'Model': name,
            'Best MAE': f"{mae:.6f}" if isinstance(mae, float) else mae,
            'Epoch': epoch
        })

df = pd.DataFrame(results)
print("\n" + "="*60)
print("ðŸ“Š 2Mæ•°æ®å®žéªŒç»“æžœæ±‡æ€»")
print("="*60)
print(df.to_string(index=False))
print("="*60)

# è®¡ç®—æå‡
if len(results) >= 2:
    for i in range(0, len(results), 2):
        if i+1 < len(results):
            baseline_mae = float(results[i]['Best MAE'])
            flow_mae = float(results[i+1]['Best MAE'])
            improvement = (baseline_mae - flow_mae) / baseline_mae * 100
            print(f"\n{results[i]['Model']} â†’ {results[i+1]['Model']}")
            print(f"æå‡: {improvement:.1f}%")
```

---

## âš™ï¸ å‚æ•°è°ƒä¼˜å»ºè®®

### å¦‚æžœé‡åˆ°OOM (Out of Memory)

```python
# å‡å°batch size
--batch_size 16  # æˆ– 8

# å‡å°hidden dimension
--hidden_dim 32

# å‡å°åºåˆ—é•¿åº¦
--closeness_len 6
```

### å¦‚æžœæƒ³åŠ é€Ÿè®­ç»ƒ

```python
# å‡å°‘epochs
--epochs 50

# ä½¿ç”¨æ›´å¤§çš„batch sizeï¼ˆå¦‚æžœæ˜¾å­˜å¤Ÿï¼‰
--batch_size 64

# ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆéœ€è¦ä¿®æ”¹ä»£ç ï¼‰
```

### æœ€ä½³é…ç½®ï¼ˆåŸºäºŽST-ResNetç»éªŒï¼‰

```python
# DCRNNæœ€ä½³é…ç½®
--lr 0.001 --alpha 0.02 --batch_size 32

# STFormeræœ€ä½³é…ç½®
--lr 0.001 --alpha 0.02 --batch_size 32
```

---

## ðŸ“Š é¢„æœŸç»“æžœï¼ˆåŸºäºŽST-ResNet scalingï¼‰

| Model | 96k Baseline | 96k +Flow | 2M Baseline | 2M +Flow | æå‡å¹…åº¦ |
|-------|-------------|-----------|-------------|----------|---------|
| ST-ResNet | 0.00610 | 0.00408 | 0.00298 | 0.00134 | 33%â†’55% |
| DCRNN | ~0.0060 | ~0.0040 | ~0.0025 | ~0.0012 | é¢„æœŸ50%+ |
| STFormer | ~0.0055 | ~0.0038 | ~0.0022 | ~0.0010 | é¢„æœŸ55%+ |

---

## ðŸš€ å¹¶è¡Œè®­ç»ƒç­–ç•¥

### æ–¹æ¡ˆAï¼šå¼€4ä¸ªColab Notebookå¹¶è¡Œ
```
Notebook 1: DCRNN baseline
Notebook 2: DCRNN + Flow
Notebook 3: STFormer baseline
Notebook 4: STFormer + Flow
```

### æ–¹æ¡ˆBï¼šé¡ºåºè®­ç»ƒï¼ˆèŠ‚çœèµ„æºï¼‰
```
Day 1: DCRNN baseline + Flow
Day 2: STFormer baseline + Flow
Day 3: åˆ†æžç»“æžœ
```

---

## ðŸ’¡ é‡è¦æç¤º

1. **å®šæœŸä¿å­˜checkpointåˆ°Drive**ï¼šé˜²æ­¢Colabæ–­çº¿ä¸¢å¤±ç»“æžœ
2. **ç›‘æŽ§è®­ç»ƒæ›²çº¿**ï¼šç¡®ä¿lossåœ¨ä¸‹é™
3. **è®°å½•è¶…å‚æ•°**ï¼šæ¯ä¸ªå®žéªŒçš„é…ç½®éƒ½è¦è®°å½•
4. **å¯¹æ¯”96kç»“æžœ**ï¼šçœ‹æå‡æ˜¯å¦ç¬¦åˆé¢„æœŸ

---

## ðŸŽ¯ ä¸‹ä¸€æ­¥

1. **å‡†å¤‡2Mæ•°æ®**ï¼ˆä¸Šä¼ åˆ°Driveæˆ–GitHub LFSï¼‰
2. **æ‰“å¼€Colab**ï¼šhttps://colab.research.google.com
3. **å¤åˆ¶Cell 1-11**ï¼Œå¼€å§‹è®­ç»ƒ
4. **ç­‰å¾…ç»“æžœ**ï¼ˆé¢„è®¡æ¯ä¸ªæ¨¡åž‹4-6å°æ—¶ï¼‰

å‡†å¤‡å¥½äº†å—ï¼Ÿå¼€å§‹2Mæ•°æ®çš„å¤§è§„æ¨¡å®žéªŒï¼ ðŸš€
